{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =open(\"Data\\OpinRankDatasetWithJudgments\\examples/2007_dodge_caliber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTXT(text):\n",
    "    q=\"\"\n",
    "    txt=\"\"\n",
    "    real_txt=[]\n",
    "    n=0\n",
    "    write=False\n",
    "    for i in tqdm(text):\n",
    "        q+=i\n",
    "        if q.find(\"<TEXT>\")>0:\n",
    "            write=True\n",
    "            q=\"\"\n",
    "            n+=1\n",
    "        if q.find(\"</TEXT>\")>0:\n",
    "            write=False\n",
    "            q=\"\"\n",
    "            txt=txt.replace(\"</TEXT\",\"\")\n",
    "            real_txt.append(txt)\n",
    "            txt=\"\"\n",
    "        if write==True:\n",
    "            txt+=i\n",
    "    return real_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 198491/198491 [00:00<00:00, 622608.08it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_txt=prepareTXT(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "words=[]\n",
    "for i in range(len(prep_txt)):\n",
    "    sentences.append(sent_tokenize(prep_txt[i]))\n",
    "for i in range(len(sentences)):\n",
    "    words.append(word_tokenize(prep_txt[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43833432, 75615000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= gensim.models.Word2Vec(words,size=300,window=5,min_count=3,workers=50)\n",
    "model.train(words,total_examples=len(sentences),epochs=2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs=model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.2951616644859314),\n",
       " ('etc', 0.2321232557296753),\n",
       " ('Good', 0.20847481489181519),\n",
       " ('most', 0.20363196730613708),\n",
       " ('the', 0.19480182230472565),\n",
       " ('easily', 0.19058889150619507),\n",
       " ('bad', 0.1859208643436432),\n",
       " ('sharp', 0.18349409103393555),\n",
       " ('loud', 0.1803836226463318),\n",
       " ('nice', 0.1786898374557495)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs.most_similar(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
